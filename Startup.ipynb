{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN Model - All letters and digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabdefghnqrt'\n",
    "num_classes = 47 \n",
    "img_size = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\kristiyan vachev\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 12, 12, 12)        312       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 5, 5, 18)          1962      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 5, 18)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 24)          1752      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 150)               57750     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 47)                7097      \n",
      "=================================================================\n",
      "Total params: 68,873\n",
      "Trainable params: 68,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters=12, kernel_size=(5,5), strides=2, activation='relu', input_shape=(img_size,img_size,1)))\n",
    "model.add(keras.layers.Dropout(.5))\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters=18, kernel_size=(3,3) , strides=2, activation='relu'))\n",
    "model.add(keras.layers.Dropout(.5))\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters=24, kernel_size=(2,2), activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(units=150, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "model.load_weights('model-all-30-epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_all = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.engine.sequential.Sequential"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN Model - Capital letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ' ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "num_classes = 27 \n",
    "img_size = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 12)        312       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 5, 5, 18)          1962      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 5, 5, 18)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 24)          1752      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 150)               57750     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 27)                4077      \n",
      "=================================================================\n",
      "Total params: 65,853\n",
      "Trainable params: 65,853\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters=12, kernel_size=(5,5), strides=2, activation='relu', input_shape=(img_size,img_size,1)))\n",
    "model.add(keras.layers.Dropout(.5))\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters=18, kernel_size=(3,3) , strides=2, activation='relu'))\n",
    "model.add(keras.layers.Dropout(.5))\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters=24, kernel_size=(2,2), activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(units=150, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "model.load_weights('model-letters-20-epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_letters = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.engine.sequential.Sequential"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image to EMNIST format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter\n",
    "\n",
    "def image_to_emnist(im):\n",
    "    \"\"\"\n",
    "    This function returns the pixel values.\n",
    "    The imput is a png file location.\n",
    "    \"\"\"\n",
    "#     im = Image.open(argv).convert('L')\n",
    "    width = float(im.size[0])\n",
    "    height = float(im.size[1])\n",
    "    newImage = Image.new('L', (28, 28), (255))  # creates white canvas of 28x28 pixels\n",
    "\n",
    "    if width > height:  # check which dimension is bigger\n",
    "        # Width is bigger. Width becomes 20 pixels.\n",
    "        nheight = int(round((28.0 / width * height), 0))  # resize height according to ratio width\n",
    "        if (nheight == 0):  # rare case but minimum is 1 pixel\n",
    "            nheight = 1\n",
    "            # resize and sharpen\n",
    "        img = im.resize((28, nheight), Image.ANTIALIAS).filter(ImageFilter.SHARPEN)\n",
    "        wtop = int(round(((28 - nheight) / 2), 0))  # calculate horizontal position\n",
    "        newImage.paste(img, (0, wtop))  # paste resized image on white canvas\n",
    "    else:\n",
    "        # Height is bigger. Heigth becomes 20 pixels.\n",
    "        nwidth = int(round((28.0 / height * width), 0))  # resize width according to ratio height\n",
    "        if (nwidth == 0):  # rare case but minimum is 1 pixel\n",
    "            nwidth = 1\n",
    "            # resize and sharpen\n",
    "        img = im.resize((nwidth, 28), Image.ANTIALIAS).filter(ImageFilter.SHARPEN)\n",
    "        wleft = int(round(((28 - nwidth) / 2), 0))  # caculate vertical pozition\n",
    "        newImage.paste(img, (wleft, 0))  # paste resized image on white canvas\n",
    "\n",
    "    # newImage.save(\"sample.png\n",
    "\n",
    "    tv = list(newImage.getdata())  # get pixel values\n",
    "\n",
    "    # normalize pixels to 0 and 1. 0 is pure white, 1 is pure black.\n",
    "    tva = [(255 - x) * 1.0 / 255.0 for x in tv]\n",
    "    return tva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(img):\n",
    "    img_flip = img.reshape(28, 28)\n",
    "    plt.imshow(img_flip, cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prediction(img):\n",
    "    result = np.argmax(model.predict(img))\n",
    "    confidence = max(model.predict(img)[0])\n",
    "    \n",
    "    return result, confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgPath = './sample_images/f.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(imgPath).convert('L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_emnist = np.array(image_to_emnist(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: F , Confidence: 0.6614873\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADOxJREFUeJzt3W+oHfWdx/HP594kYGwQpZiNNm3aoEsXyabrRRZaFhe12KUQK1SaR1la9go2sIVFVnxSYSmUZVtXfBBNMeQWGtuCcQ2l9A+x1DwoYqK1WrNtRLLp3YRkNYVaEnJv7v3ugzspt8k9M+eemTlzbr7vF4RzzvzmzHwzyefMnPObmZ8jQgDyGeu6AADdIPxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5JaNcyV2eZ0QqBlEeF+5qu157d9r+3f2H7b9iN1lgVguDzouf22xyX9VtI9kqYlvSJpe0S8VfIe9vxAy4ax579D0tsR8U5EzEj6rqRtNZYHYIjqhP9mSb9b9Hq6mPZnbE/aPmz7cI11AWhYnR/8ljq0uOKwPiJ2S9otcdgPjJI6e/5pSRsXvf6QpJP1ygEwLHXC/4qkW2x/1PYaSV+QdKCZsgC0beDD/oi4aHunpB9LGpe0JyJ+3VhlAFo1cFffQCvjOz/QuqGc5ANg5SL8QFKEH0iK8ANJEX4gKcIPJDXU6/mx8oyNle8fqrqKV63q7r9YWW0XL14cYiWjiT0/kBThB5Ii/EBShB9IivADSRF+ICmu6rsKrF69umfb+Ph46XtnZ2dL2+fm5gaqCd3hqj4ApQg/kBThB5Ii/EBShB9IivADSRF+ICn6+dGqjRs39myre7nvhQsXSttPnsw5hgz9/ABKEX4gKcIPJEX4gaQIP5AU4QeSIvxAUrU6Wm0fl/S+pDlJFyNioomirjZ2ebdr3XMttm7d2rNtamqq9L1btmypte6rVdW/2Zo1a0rbZ2ZmmiynFU3cVP3vI+LdBpYDYIg47AeSqhv+kPQT20dsTzZREIDhqHvY/8mIOGn7Rkk/tf3fEfHS4hmKDwU+GIARU2vPHxEni8czkp6XdMcS8+yOiAl+DARGy8Dht32t7XWXnkv6tKQ3myoMQLvqHPavl/R80SWyStK+iPhRI1UBaN3A4Y+IdyT9dYO1XLXq9uO/9tprpe1l/fxVzp07V9r+1FNPlbY/8cQTpe0nTpxYdk1Nuf3223u2vffee7WWfTUM8U1XH5AU4QeSIvxAUoQfSIrwA0kRfiCpJq7qQ02PP/54aXtVV95DDz3Us23Xrl0D1XQ1OHLkSGvLnp+fb23Zw8KeH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSYojuPq1evbpn2+zsbOl7d+zYUdq+d+/e0vaDBw+Wtt99992l7WXK/l6SND4+Xto+NzdX2l7WH173/17V7bXHxnrv26rWvZIv2WWIbgClCD+QFOEHkiL8QFKEH0iK8ANJEX4gKfr5+1TWp1y1Davaz58/X9q+du3a0nZgMfr5AZQi/EBShB9IivADSRF+ICnCDyRF+IGkKu/bb3uPpM9KOhMRtxXTbpD0PUmbJB2X9EBE/L69MttX97r1Oh5++OFa71+3bl3PtqpzCKquia+6VwFWrn72/Hsl3XvZtEckHYyIWyQdLF4DWEEqwx8RL0k6e9nkbZKmiudTku5ruC4ALRv0O//6iDglScXjjc2VBGAYWh+rz/akpMm21wNgeQbd85+2vUGSisczvWaMiN0RMREREwOuC0ALBg3/AUmXbkm7Q9ILzZQDYFgqw2/7WUm/kPSXtqdtf0nS1yXdY/uYpHuK1wBWEK7nb8DOnTtL25988snS9qq+dmA5uJ4fQCnCDyRF+IGkCD+QFOEHkiL8QFJ09TXg9ddfL23fsmVLaXtVV9/mzZtL28uGk161qvwM7ptuuqm0/dChQ6XtGD109QEoRfiBpAg/kBThB5Ii/EBShB9IivADSbV+G68mrVmzpmfbzMxM6Xv37dtX2r59+/aBamrCMM+1WK677rqrtP3FF18sba/zb4Z2secHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaRW1PX8Y2O9P6vm5+frLFr3339/afv+/ft7tj399NOl752cLB+tjFt3o0lczw+gFOEHkiL8QFKEH0iK8ANJEX4gKcIPJFXZz297j6TPSjoTEbcV0x6T9E+S/q+Y7dGI+GHlyq7S+/ZXbcNjx46Vtt96661NloPkmuzn3yvp3iWmPx4RW4s/lcEHMFoqwx8RL0k6O4RaAAxRne/8O23/yvYe29c3VhGAoRg0/LskbZa0VdIpSd/oNaPtSduHbR8ecF0AWjBQ+CPidETMRcS8pG9JuqNk3t0RMRERE4MWCaB5A4Xf9oZFLz8n6c1mygEwLJW37rb9rKQ7JX3Q9rSkr0q60/ZWSSHpuKQHW6wRQAsqwx8RS93Q/pkWamlV1TXz11xzTWn7uXPnBl739PT0wO+VpLVr15a2nz9/vmdb3XsF1L1PAkYXZ/gBSRF+ICnCDyRF+IGkCD+QFOEHklpRQ3TXUXXZ7YULF1pbd1U3YpWq7rayv9soD/+NbrHnB5Ii/EBShB9IivADSRF+ICnCDyRF+IGk0vTzd2lmZqbrEoArsOcHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaTo5x+C6667rusSgCuw5weSIvxAUoQfSIrwA0kRfiApwg8kRfiBpCr7+W1vlPRtSX8haV7S7oh4wvYNkr4naZOk45IeiIjft1dqu+oOZV1mdna2tWUDg+pnz39R0r9ExMcl/a2kL9v+K0mPSDoYEbdIOli8BrBCVIY/Ik5FxKvF8/clHZV0s6RtkqaK2aYk3ddWkQCat6zv/LY3SfqEpJclrY+IU9LCB4SkG5suDkB7+j633/YHJD0n6SsR8Yd+vyPbnpQ0OVh5ANrS157f9motBP87EbG/mHza9oaifYOkM0u9NyJ2R8REREw0UTCAZlSG3wu7+GckHY2Iby5qOiBpR/F8h6QXmi8PQFtcNYSz7U9JOiTpDS109UnSo1r43v99SR+WdELS5yPibMWyGC8aaFlE9PWdvDL8TSL8QPv6DT9n+AFJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5JiiO4GjI2Vf4bOz8+XtgNdYM8PJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0nRz98A+vGxErHnB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkKsNve6Ptn9k+avvXtv+5mP6Y7f+1/cvizz+0Xy6ApjgiymewN0jaEBGv2l4n6Yik+yQ9IOmPEfEffa/MLl8ZgNoiwv3MV3mGX0ScknSqeP6+7aOSbq5XHoCuLes7v+1Nkj4h6eVi0k7bv7K9x/b1Pd4zafuw7cO1KgXQqMrD/j/NaH9A0s8lfS0i9tteL+ldSSHp37Tw1eCLFcvgsB9oWb+H/X2F3/ZqST+Q9OOI+OYS7Zsk/SAibqtYDuEHWtZv+Pv5td+SnpF0dHHwix8CL/mcpDeXWySA7vTza/+nJB2S9IakS9euPippu6StWjjsPy7pweLHwbJlsecHWtboYX9TCD/QvsYO+wFcnQg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJDXuI7ncl/c+i1x8spo2iUa1tVOuSqG1QTdb2kX5nHOr1/Fes3D4cEROdFVBiVGsb1bokahtUV7Vx2A8kRfiBpLoO/+6O119mVGsb1bokahtUJ7V1+p0fQHe63vMD6Egn4bd9r+3f2H7b9iNd1NCL7eO23yhGHu50iLFiGLQztt9cNO0G2z+1fax4XHKYtI5qG4mRm0tGlu50243aiNdDP+y3PS7pt5LukTQt6RVJ2yPiraEW0oPt45ImIqLzPmHbfyfpj5K+fWk0JNv/LulsRHy9+OC8PiL+dURqe0zLHLm5pdp6jSz9j+pw2zU54nUTutjz3yHp7Yh4JyJmJH1X0rYO6hh5EfGSpLOXTd4maap4PqWF/zxD16O2kRARpyLi1eL5+5IujSzd6bYrqasTXYT/Zkm/W/R6WqM15HdI+ontI7Ynuy5mCesvjYxUPN7YcT2Xqxy5eZguG1l6ZLbdICNeN62L8C81msgodTl8MiL+RtJnJH25OLxFf3ZJ2qyFYdxOSfpGl8UUI0s/J+krEfGHLmtZbIm6OtluXYR/WtLGRa8/JOlkB3UsKSJOFo9nJD2vha8po+T0pUFSi8czHdfzJxFxOiLmImJe0rfU4bYrRpZ+TtJ3ImJ/MbnzbbdUXV1tty7C/4qkW2x/1PYaSV+QdKCDOq5g+9rihxjZvlbSpzV6ow8fkLSjeL5D0gsd1vJnRmXk5l4jS6vjbTdqI153cpJP0ZXxn5LGJe2JiK8NvYgl2P6YFvb20sIVj/u6rM32s5Lu1MJVX6clfVXSf0n6vqQPSzoh6fMRMfQf3nrUdqeWOXJzS7X1Gln6ZXW47Zoc8bqRejjDD8iJM/yApAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyT1/7FfDHxLaF0vAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result, confidence = run_prediction(img_emnist.reshape(1,28,28,1))\n",
    "print('Prediction:', classes[result], ', Confidence:', confidence)\n",
    "show_img(img_emnist.reshape(1,28,28,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Larger pictures - Sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgPath = './sample_images/letters_capital.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(imgPath).convert('L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379 265\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=379x265 at 0x24E6BCF1E48>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(img.size[0], img.size[1])\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowSizes = [120, 100, 80]\n",
    "stride = 20\n",
    "treshold = 0.9\n",
    "\n",
    "width = img.size[0]\n",
    "height = img.size[1]\n",
    "\n",
    "found = []\n",
    "\n",
    "for windowSize in windowSizes:\n",
    "    for y in range(0, int(height) - windowSize + 1, stride):\n",
    "        for x in range(0, int(width) - windowSize + 1, stride):\n",
    "            newWindow = img.crop((x, y, x + windowSize, y + windowSize))\n",
    "            emnistImg = np.array(image_to_emnist(newWindow))\n",
    "\n",
    "            currLabel, currConfidence = run_prediction(emnistImg.reshape(1,28,28,1))\n",
    "\n",
    "            if currConfidence > treshold:\n",
    "                found.append({'char': classes[currLabel], 'conf': currConfidence, 'x': x, 'y': y, 'size': windowSize})\n",
    "\n",
    "#                 print('X:', x, 'Y:', y, 'Prediction:',classes[currLabel], 'Confidence:', currConfidence)\n",
    "#                 display(newWindow)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick best detections and sort alphabetically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F', 'G', 'K', 'M', 'P', 'T', 'Z']\n"
     ]
    }
   ],
   "source": [
    "windows = found\n",
    "keepWindow = [True] * len(windows)\n",
    "\n",
    "for i in range(len(windows)):\n",
    "    for j in range(i+1, len(windows)):\n",
    "        #Same size\n",
    "        if windows[i]['size'] == windows[j]['size']:\n",
    "            #check if distance is less than half\n",
    "            if abs(windows[i]['x'] - windows[j]['x']) < windows[i]['size'] / 2 and abs(windows[i]['y'] - windows[j]['y']) < windows[i]['size'] / 2:\n",
    "                if windows[i]['conf'] > windows[j]['conf']:\n",
    "                    keepWindow[j] = False\n",
    "                else:\n",
    "                    keepWindow[i] = False\n",
    "        #Smaller\n",
    "        else:\n",
    "            if abs(windows[i]['x'] - windows[j]['x']) < windows[i]['size'] / 2 and abs(windows[i]['y'] - windows[j]['y']) < windows[i]['size'] / 2:\n",
    "                keepWindow[j] = False\n",
    "                \n",
    "result = []                \n",
    "for i in range(len(windows)):\n",
    "    if keepWindow[i]:\n",
    "        result.append(windows[i]['char'])\n",
    "        \n",
    "print(sorted(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=379x265 at 0x24E6BCF1E48>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
